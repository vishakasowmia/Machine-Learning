{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23311df4",
   "metadata": {},
   "source": [
    "# Customized Sequential CNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aabfd4",
   "metadata": {},
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101c99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95a54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation and preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "090d0d1a",
   "metadata": {},
   "source": [
    "*Rescale = 1 / 255.0\n",
    "By dividing each pixel value by 255.0, this parameter rescales the image's pixel values. With this procedure, the pixel values are normalized to fall between [0, 1]. During preprocessing, normalization is frequently used to make sure that all input values fall within the same range.\n",
    "\n",
    "*Rotation_range=20:\n",
    "The range (in degrees) for the random rotations of the input images is specified by this parameter. It permits random rotations of up to 20 degrees in either direction in this instance.\n",
    "\n",
    "\n",
    "*width_shift_range=0.2:\n",
    "The amount of the overall width within which the image can be adjusted horizontally is specified. It permits horizontal movements of up to 20% of the overall width in this instance.\n",
    "\n",
    "*height_shift_range=0.2:\n",
    "This option sets a range for vertical shifts as a percentage of the entire height, similar to width_shift_range. Up to 20% of the overall height can be moved vertically.\n",
    "\n",
    "*shear_range=0.2:\n",
    "A sort of transformation called shear distorts the shape of the image. The maximum shear intensity is regulated by this parameter. With a value of 0.2, shear transformations can cause an image distortion of up to 20%.\n",
    "\n",
    "*zoom_range=0.2:\n",
    "This setting regulates the image's zoom range during arbitrary zooming. An picture can be zoomed in or out by up to 20% when the value is 0.2.\n",
    "\n",
    "*horizontal_flip=True:\n",
    "\n",
    "It permits a 50% chance of randomly flipping the image horizontally. The training dataset's variety may be improved by this operation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22a00a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the folder\n",
    "batch_size = 32  # Adjust batch size as needed\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    \"C://Users//DELL//Downloads//archive (5)//Training\",\n",
    "    target_size=(64, 64),  # Resize images to the desired size\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Use 'binary' for binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2f92a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train model1 using model.fit() with appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fcc9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your optimizer (e.g., Adam) and loss function (e.g., categorical_crossentropy)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "loss = 'categorical_crossentropy'  # Use 'binary_crossentropy' for binary classification\n",
    "\n",
    "# Compile the model with the specified optimizer and loss\n",
    "model1.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Now, you can proceed with training and evaluation."
   ]
  },
  {
   "cell_type": "raw",
   "id": "42f78e65",
   "metadata": {},
   "source": [
    "#Load the model with binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e13f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1311 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    \"C://Users//DELL//Downloads//archive (5)//Testing\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Use 'binary' for binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a25c9ba7",
   "metadata": {},
   "source": [
    "Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab5ced9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "179/179 [==============================] - 118s 649ms/step - loss: 1.1714 - accuracy: 0.5116\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 39s 216ms/step - loss: 0.8890 - accuracy: 0.6415\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 38s 211ms/step - loss: 0.8096 - accuracy: 0.6770\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 97s 546ms/step - loss: 0.7493 - accuracy: 0.7050\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 38s 212ms/step - loss: 0.7162 - accuracy: 0.7190\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 38s 213ms/step - loss: 0.7088 - accuracy: 0.7169\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 38s 213ms/step - loss: 0.6855 - accuracy: 0.7248\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 38s 213ms/step - loss: 0.6634 - accuracy: 0.7414\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 38s 213ms/step - loss: 0.6638 - accuracy: 0.7334\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 38s 213ms/step - loss: 0.6422 - accuracy: 0.7479\n",
      "41/41 [==============================] - 25s 612ms/step - loss: 0.7541 - accuracy: 0.6766\n",
      "Test Accuracy for Model 1: 0.6765827536582947\n"
     ]
    }
   ],
   "source": [
    "# Create a CNN model (customize this model for each of your five models)\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = 'categorical_crossentropy'\n",
    "model1.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "model1.fit(train_generator, epochs=epochs)\n",
    "\n",
    "# Load and preprocess your test data (similar to training data)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model1.evaluate(test_generator)\n",
    "print(f\"Test Accuracy for Model 1: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2506b266",
   "metadata": {},
   "source": [
    "* A CNN model should be made (model1):\n",
    "The tf.keras.Sequential API is used in this code to define a CNN model referred to as model1. It has a straightforward CNN architecture with the following layers:\n",
    "\n",
    "1. (tf.keras.layers.Conv2D) Convolutional Layer This layer uses ReLU activation, 32 filters of size (3, 3), and a convolution    operation. The input picture shape is specified by the input_shape argument as (64, 64, 3), which stands for 64x64 pixels with three RGB color channels.\n",
    "2. The MaxPooling Layer (tf.keras.layers.MaxPooling2D) reduces the spatial dimensions of the feature maps by performing max-pooling with a pool size of (2, 2).\n",
    "3. The 1D vector created by the Flatten Layer (tf.keras.layers.Flatten) flattens the 2D feature maps.\n",
    "4. Dense Layers (tf.keras.layers.Dense): Two dense layers are introduced, the hidden layer having 128 units with ReLU activation, and the output layer having num_classes units and a softmax activation. The classification problem's total number of classes is denoted by the variable num_classes.\n",
    "5.Model Construction: \n",
    "The Adam optimizer (tf.keras.optimizers.Adam) is used to construct the model, using a learning rate of 0.001. Categorical cross-entropy ('categorical_crossentropy'), a popular loss function for multi-class classification issues, was selected as the loss function. Accuracy is also listed as a measure to keep an eye on during training.\n",
    "6.Develop the Model:\n",
    "The fit approach is used to train the model. On the training data supplied by train_generator, it has been trained over a total of 10 epochs. A full traverse across the entire training dataset constitutes one epoch."
   ]
  },
  {
   "cell_type": "raw",
   "id": "66befb5a",
   "metadata": {},
   "source": [
    "Model 2: Deeper CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54b0d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model2\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed8fa1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "179/179 [==============================] - 32s 176ms/step - loss: 1.0812 - accuracy: 0.5156\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 40s 221ms/step - loss: 0.8108 - accuracy: 0.6756\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 45s 252ms/step - loss: 0.7270 - accuracy: 0.7066\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 49s 275ms/step - loss: 0.6801 - accuracy: 0.7283\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 45s 253ms/step - loss: 0.6276 - accuracy: 0.7526\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 48s 267ms/step - loss: 0.6224 - accuracy: 0.7539\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 41s 227ms/step - loss: 0.5588 - accuracy: 0.7799\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 50s 279ms/step - loss: 0.5347 - accuracy: 0.7980\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 61s 340ms/step - loss: 0.5178 - accuracy: 0.8039\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 64s 358ms/step - loss: 0.4999 - accuracy: 0.8050\n",
      "41/41 [==============================] - 7s 158ms/step - loss: 0.6507 - accuracy: 0.7658\n",
      "Test Accuracy for Model 2: 0.7658275961875916\n"
     ]
    }
   ],
   "source": [
    "# Compile model2\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = 'categorical_crossentropy'\n",
    "model2.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train model2\n",
    "epochs = 10\n",
    "model2.fit(train_generator, epochs=epochs)\n",
    "\n",
    "# Load and preprocess your test data (similar to training data)\n",
    "\n",
    "# Evaluate model2 on test data\n",
    "test_loss, test_accuracy = model2.evaluate(test_generator)\n",
    "print(f\"Test Accuracy for Model 2: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A Conv2D layer with 64 filters, each with a size of (3, 3), makes up the top layer. It makes use of ReLU activation. Convolutional learning of picture features is done by this layer.\n",
    "A MaxPooling2D layer with a (2, 2) pool size follows the convolutional layer. The feature maps' spatial dimensions are reduced through max pooling.\n",
    "The next step is to add a second Conv2D layer, this time with 128 filters and ReLU activation.\n",
    "a second MaxPooling2D layer follows.\n",
    "The 2D feature maps are converted into a 1D vector by the following layer, Flatten. The reason for this is that the layers below are completely interconnected.\n",
    "Following are two dense (completely linked) layers:\n",
    "256 units in the top Dense layer have ReLU activation. In order to learn high-level representations from the flattened features, it acts as a feature extractor.\n",
    "The number of classes in your classification challenge is reflected in the num_classes units of the final Dense layer. Softmax, a suitable activation function for multi-class classification tasks, is applied in this case. For each input, it produces class probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64606485",
   "metadata": {},
   "source": [
    "Transfer Learning with Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "260e96d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Define MobileNetV2 as the base model\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Create model3 by adding layers on top of the base model\n",
    "model3 = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f11f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "179/179 [==============================] - 67s 311ms/step - loss: 0.8358 - accuracy: 0.6882\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 55s 305ms/step - loss: 0.4823 - accuracy: 0.8295\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 60s 333ms/step - loss: 0.3795 - accuracy: 0.8612\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 66s 369ms/step - loss: 0.3155 - accuracy: 0.8850\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 86s 480ms/step - loss: 0.2907 - accuracy: 0.8999\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 83s 463ms/step - loss: 0.2695 - accuracy: 0.9086\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 78s 437ms/step - loss: 0.2458 - accuracy: 0.9135\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 91s 509ms/step - loss: 0.1988 - accuracy: 0.9240\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 72s 403ms/step - loss: 0.2086 - accuracy: 0.9263\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 77s 430ms/step - loss: 0.2014 - accuracy: 0.9317\n",
      "41/41 [==============================] - 7s 133ms/step - loss: 4.8957 - accuracy: 0.6255\n",
      "Test Accuracy for Model 3: 0.6254767179489136\n"
     ]
    }
   ],
   "source": [
    "# Compile model3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = 'categorical_crossentropy'\n",
    "model3.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train model3\n",
    "epochs = 10\n",
    "model3.fit(train_generator, epochs=epochs)\n",
    "\n",
    "# Load and preprocess your test data (similar to training data)\n",
    "\n",
    "# Evaluate model3 on test data\n",
    "test_loss, test_accuracy = model3.evaluate(test_generator)\n",
    "print(f\"Test Accuracy for Model 3: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e061bc33",
   "metadata": {},
   "source": [
    "*Make MobileNetV2 the Base Model:\n",
    "The MobileNetV2 model is referred to as the base model in the code. For applications like picture classification, a common pre-trained convolutional neural network architecture called MobileNetV2 is frequently utilized. Pre-trained weights from the ImageNet dataset are already loaded into it.\n",
    "The MobileNetV2 model's fully connected layers—the top layers—are disregarded by using the include_top=False option. On top of this foundation model, we'll add the custom layers we'll need for the particular task.\n",
    "The model expects input images to be 64x64 pixels with 3 color channels (RGB), as specified by the input_shape parameter, which sets the input image shape as (64, 64, 3).\n",
    "\n",
    "*By Adding Layers on Top of the Base Model, Create Model 3:\n",
    "A Sequential model is developed for model 3.\n",
    "Model3's initial layer is the foundation model (MobileNetV2 sans its top layers).\n",
    "There is a new layer called Global Average Pooling 2D (tf.keras.layers.GlobalAveragePooling2D). This layer creates a fixed-size vector by averaging the spatial dimensions of the feature maps from the base model.\n",
    "The Global Average Pooling layer is followed by two Dense (completely linked) layers. The first dense layer utilizes ReLU activation and has 256 units, whereas the second dense layer employs softmax activation and has num_classes units. The number of classes in your classification problem is indicated by the variable num_classes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "761bf725",
   "metadata": {},
   "source": [
    "Custom Architecture with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baf3883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model4 with Conv2D, BatchNormalization, and Dropout layers\n",
    "model4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e0d5afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "179/179 [==============================] - 42s 230ms/step - loss: 6.6729 - accuracy: 0.4888\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 54s 303ms/step - loss: 2.6258 - accuracy: 0.5198\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 79s 438ms/step - loss: 1.7522 - accuracy: 0.5495\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 79s 438ms/step - loss: 1.4397 - accuracy: 0.5629\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 78s 432ms/step - loss: 1.5720 - accuracy: 0.5958\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 78s 433ms/step - loss: 1.1852 - accuracy: 0.6162\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 79s 438ms/step - loss: 1.2783 - accuracy: 0.6415\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 80s 445ms/step - loss: 1.3065 - accuracy: 0.6418\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 78s 433ms/step - loss: 1.2160 - accuracy: 0.6609\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 76s 426ms/step - loss: 1.2611 - accuracy: 0.6733\n",
      "41/41 [==============================] - 8s 170ms/step - loss: 1.2084 - accuracy: 0.6506\n",
      "Test Accuracy for Model 4: 0.6506483554840088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile model4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = 'categorical_crossentropy'\n",
    "model4.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train model4\n",
    "epochs = 10\n",
    "model4.fit(train_generator, epochs=epochs)\n",
    "\n",
    "# Load and preprocess your test data (similar to training data)\n",
    "\n",
    "# Evaluate model4 on test data\n",
    "test_loss, test_accuracy = model4.evaluate(test_generator)\n",
    "print(f\"Test Accuracy for Model 4: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6850a8b8",
   "metadata": {},
   "source": [
    "*Construct model4 with BatchNormalization, Dropout Layers, and Conv2D:\n",
    "\n",
    "Model4 is classified as a sequential model, which indicates that layers are added sequentially one at a time.\n",
    "Conv2D layer with 64 filters, each of size (3, 3), and ReLU activation make up the model's foundation. The input_shape is set to (64, 64, 3), suggesting that it anticipates receiving RGB images with a resolution of 64x64 pixels.\n",
    "Following the initial Conv2D layer comes a BatchNormalization layer. Batch normalization aids in training acceleration and stability.\n",
    "By picking the highest value contained within a 2x2 frame, the MaxPooling2D layer lowers the spatial dimensions.\n",
    "A portion of the input units are randomly set to 0 during each update when dropout is applied at a rate of 0.25. \n",
    "\n",
    "*Additional Convolutional Layers with MaxPooling and BatchNormalization:\n",
    "\n",
    "*BatchNormalization and MaxPooling are applied after the addition of a second Conv2D layer with 128 filters and ReLU activation.\n",
    "These layers aid the model's ability to extract from the data hierarchical features.\n",
    "Dense and Flatten Layers:\n",
    "\n",
    "*The 2D feature maps are transformed into a 1D vector by the Flatten layer and then fed into a dense (completely linked) layer.\n",
    "The addition of a dense layer with 256 units and ReLU activation. This layer functions as an extractor of features.\n",
    "To further prevent overfitting, dropout is performed once more at a rate of 0.5.\n",
    "\n",
    "*Result Layer:\n",
    "\n",
    "The number of classes in your classification challenge is reflected in the num_classes units of the final Dense layer. Softmax, a suitable activation function for multi-class classification, is employed."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7304415",
   "metadata": {},
   "source": [
    "#Larger Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6b650cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 6s 134ms/step - loss: 1.3918 - accuracy: 0.2372\n",
      "Test Accuracy for Model 5: 0.23722349107265472\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes in your dataset\n",
    "num_classes = 4  # Replace 4 with the actual number of classes in your dataset\n",
    "\n",
    "# Define and compile model5\n",
    "model5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "model5.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Now, you can proceed with training and evaluation as previously shown\n",
    "\n",
    "# Evaluate the model on your test dataset\n",
    "# Replace 'test_generator' with your actual test data generator\n",
    "test_loss, test_accuracy = model5.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Accuracy for Model 5: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0678428",
   "metadata": {},
   "source": [
    "Since model 5 is a sequential model, layers are added one after the other.\n",
    "*Conv2D layer with 128 filters, each of size (3, 3), and ReLU activation make up the model's foundation. The input_shape is set to (64, 64, 3), suggesting that it anticipates receiving RGB images with a resolution of 64x64 pixels.\n",
    "*The next layer, MaxPooling2D, decreases the spatial dimensions by taking the highest value contained inside a 2x2 frame.\n",
    "*Conv2D layer is followed by MaxPooling2D twice more in this design. These layers aid the model's ability to extract from the data hierarchical features.\n",
    "*A flatten layer is applied after the convolutional layers to turn the 2D feature maps into 1D vectors.\n",
    "*As a feature extractor, a dense layer with 512 units and ReLU activation is added.\n",
    "A portion of the input units are randomly set to 0 during each update when dropout is applied at a rate of 0.5. As a result, overfitting is reduced.\n",
    "*The number of classes in your classification challenge is reflected in the num_classes units of the final Dense layer. Softmax, a suitable activation function for multi-class classification, is employed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92c8906a",
   "metadata": {},
   "source": [
    "Compare to all the model deep nerual network has more accuracy with 0.7658275961875916\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
